{
  "piqa_accuracy": 0.515625,
  "piqa_samples": 256,
  "piqa_baseline_accuracy": 0.51171875,
  "piqa_memorize_accuracy": 0.515625,
  "piqa_memorize_delta": 0.00390625,
  "piqa_titan_mem_updates": 10.03807739145368,
  "piqa_cms_fast_updates": 0.0,
  "hellaswag_accuracy": 0.30078125,
  "hellaswag_samples": 256,
  "hellaswag_baseline_accuracy": 0.296875,
  "hellaswag_memorize_accuracy": 0.30078125,
  "hellaswag_memorize_delta": 0.00390625,
  "hellaswag_titan_mem_updates": 9.644964346148374,
  "hellaswag_cms_fast_updates": 0.0,
  "winogrande_accuracy": 0.4921875,
  "winogrande_samples": 256,
  "winogrande_baseline_accuracy": 0.484375,
  "winogrande_memorize_accuracy": 0.4921875,
  "winogrande_memorize_delta": 0.0078125,
  "winogrande_titan_mem_updates": 9.799855060760141,
  "winogrande_cms_fast_updates": 0.0,
  "arc_arc-easy_accuracy": 0.28515625,
  "arc_arc-easy_samples": 256,
  "arc_arc-easy_baseline_accuracy": 0.28515625,
  "arc_arc-easy_memorize_accuracy": 0.28515625,
  "arc_arc-easy_memorize_delta": 0.0,
  "arc_arc-easy_titan_mem_updates": 9.155673045361393,
  "arc_arc-easy_cms_fast_updates": 0.0,
  "arc_arc-challenge_accuracy": 0.25,
  "arc_arc-challenge_samples": 256,
  "arc_arc-challenge_baseline_accuracy": 0.24609375,
  "arc_arc-challenge_memorize_accuracy": 0.25,
  "arc_arc-challenge_memorize_delta": 0.00390625,
  "arc_arc-challenge_titan_mem_updates": 9.186319984716842,
  "arc_arc-challenge_cms_fast_updates": 0.0,
  "boolq_accuracy": 0.3671875,
  "boolq_samples": 256,
  "boolq_baseline_accuracy": 0.3671875,
  "boolq_memorize_accuracy": 0.3671875,
  "boolq_memorize_delta": 0.0,
  "boolq_titan_mem_updates": 8.10761637164109,
  "boolq_cms_fast_updates": 0.0,
  "siqa_accuracy": 0.3125,
  "siqa_samples": 256,
  "siqa_baseline_accuracy": 0.31640625,
  "siqa_memorize_accuracy": 0.3125,
  "siqa_memorize_delta": -0.00390625,
  "siqa_titan_mem_updates": 10.038975774096901,
  "siqa_cms_fast_updates": 0.0,
  "commonsenseqa_accuracy": 0.1875,
  "commonsenseqa_samples": 256,
  "commonsenseqa_baseline_accuracy": 0.19140625,
  "commonsenseqa_memorize_accuracy": 0.1875,
  "commonsenseqa_memorize_delta": -0.00390625,
  "commonsenseqa_titan_mem_updates": 10.048177535929167,
  "commonsenseqa_cms_fast_updates": 0.0,
  "openbookqa_accuracy": 0.140625,
  "openbookqa_samples": 256,
  "openbookqa_baseline_accuracy": 0.140625,
  "openbookqa_memorize_accuracy": 0.140625,
  "openbookqa_memorize_delta": 0.0,
  "openbookqa_titan_mem_updates": 10.512614026167608,
  "openbookqa_cms_fast_updates": 0.0
}